{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf39d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\").cpu().eval()\n",
    "\n",
    "decoder = model.decoder\n",
    "\n",
    "kv_cache, hooks = decoder.install_kv_cache_hooks()\n",
    "\n",
    "tokenizer = whisper.tokenizer.get_tokenizer(True)\n",
    "\n",
    "audio = whisper.load_audio(\"sample.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "mel = whisper.log_mel_spectrogram(audio).unsqueeze(0)\n",
    "\n",
    "audio_features = model.encoder(mel)\n",
    "\n",
    "tokens = torch.tensor([[tokenizer.sot, tokenizer.no_timestamps]])\n",
    "\n",
    "logits = decoder(tokens, audio_features, kv_cache=kv_cache)\n",
    "\n",
    "result = tokens[0].tolist()\n",
    "\n",
    "for _ in range(200):\n",
    "\n",
    "    next_token = logits[:, -1].argmax(-1)\n",
    "\n",
    "    if next_token.item() == tokenizer.eot:\n",
    "        break\n",
    "\n",
    "    result.append(next_token.item())\n",
    "\n",
    "    logits = decoder(next_token.unsqueeze(0), audio_features, kv_cache=kv_cache)\n",
    "\n",
    "print(tokenizer.decode(result))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
